"""
Universal Processed Transaction Model
=====================================

Enhanced transaction model that represents a fully processed transaction from any
connector type after going through the universal transaction processing pipeline.

This model contains the original transaction data plus all enrichments, validations,
and processing metadata generated by the universal processing pipeline.

Features:
- Original transaction preservation
- Processing pipeline results
- Validation and compliance status
- Risk assessment and fraud detection results
- Business rule evaluation outcomes
- Pattern matching and categorization
- Customer matching and enrichment data
- Nigerian regulatory compliance status
"""

from typing import Dict, List, Optional, Any
from dataclasses import dataclass, field
from enum import Enum
from datetime import datetime
from decimal import Decimal

from .universal_transaction import UniversalTransaction
from ..connector_configs.connector_types import ConnectorType


class ProcessingStatus(Enum):
    """Status of transaction processing."""
    PENDING = "pending"
    VALIDATED = "validated"
    DUPLICATE = "duplicate"
    ENRICHED = "enriched"
    CATEGORIZED = "categorized"
    READY_FOR_INVOICE = "ready_for_invoice"
    FAILED = "failed"


class TransactionRisk(Enum):
    """Risk level assessment for transaction."""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"


@dataclass
class ProcessingMetadata:
    """Metadata from universal transaction processing pipeline."""
    processing_timestamp: datetime
    processing_duration: float
    pipeline_version: str
    connector_type: ConnectorType
    validation_passed: bool
    duplicate_detected: bool
    risk_level: TransactionRisk
    confidence_score: float
    processing_notes: List[str] = field(default_factory=list)
    
    # Stage-specific results
    validation_stage_duration: float = 0.0
    duplicate_detection_duration: float = 0.0
    amount_validation_duration: float = 0.0
    business_rules_duration: float = 0.0
    pattern_matching_duration: float = 0.0
    enrichment_duration: float = 0.0


@dataclass
class EnrichmentData:
    """Additional data enriched during processing."""
    # Customer matching
    customer_matched: bool = False
    customer_confidence: float = 0.0
    customer_id: Optional[str] = None
    customer_name: Optional[str] = None
    customer_type: Optional[str] = None
    
    # Transaction categorization
    primary_category: Optional[str] = None
    sub_category: Optional[str] = None
    business_purpose: Optional[str] = None
    
    # Amount analysis
    amount_risk_flags: List[str] = field(default_factory=list)
    currency_converted: bool = False
    original_currency: Optional[str] = None
    
    # Pattern matching results
    transaction_patterns: List[str] = field(default_factory=list)
    merchant_identified: bool = False
    merchant_name: Optional[str] = None
    
    # Nigerian business context
    nigerian_compliance_level: str = "unknown"  # compliant, non_compliant, requires_review
    tax_implications: List[str] = field(default_factory=list)
    regulatory_flags: List[str] = field(default_factory=list)
    
    # ERP-specific enrichments
    erp_invoice_number: Optional[str] = None
    erp_customer_code: Optional[str] = None
    erp_cost_center: Optional[str] = None
    
    # Banking-specific enrichments
    bank_account_verified: bool = False
    transaction_channel: Optional[str] = None
    
    # POS-specific enrichments
    pos_terminal_id: Optional[str] = None
    receipt_number: Optional[str] = None
    
    # CRM-specific enrichments
    service_type: Optional[str] = None
    project_id: Optional[str] = None


@dataclass
class UniversalProcessedTransaction:
    """
    Fully processed universal transaction with all pipeline enhancements.
    
    This is the primary data structure used by invoice automation components
    and represents a transaction that has been validated, enriched, and prepared
    for Nigerian regulatory compliance.
    """
    
    # Original transaction data
    original_transaction: UniversalTransaction
    
    # Processing pipeline results
    validation_result: Any  # ValidationResult from validation stage
    duplicate_result: Any   # DuplicateResult from duplicate detection
    processing_metadata: ProcessingMetadata
    enrichment_data: EnrichmentData
    
    # Final processed status
    status: ProcessingStatus
    
    # Connector type for easy access
    connector_type: ConnectorType
    
    # Computed properties for easy access
    @property
    def id(self) -> str:
        """Transaction ID."""
        return self.original_transaction.id
    
    @property
    def amount(self) -> Decimal:
        """Transaction amount as Decimal."""
        return self.original_transaction.amount_decimal
    
    @property
    def date(self) -> datetime:
        """Transaction date."""
        return self.original_transaction.date
    
    @property
    def description(self) -> str:
        """Transaction description."""
        return self.original_transaction.description
    
    @property
    def account_number(self) -> Optional[str]:
        """Account number."""
        return self.original_transaction.account_number
    
    @property
    def reference(self) -> Optional[str]:
        """Transaction reference."""
        return self.original_transaction.reference
    
    @property
    def currency(self) -> str:
        """Transaction currency."""
        return self.original_transaction.currency
    
    @property
    def source_system(self) -> str:
        """Source system identifier."""
        return self.original_transaction.source_system
    
    @property
    def category(self) -> str:
        """Transaction category (enriched if available)."""
        return (self.enrichment_data.primary_category or 
                self.original_transaction.category or 
                "unknown")
    
    # Validation and status methods
    
    def is_valid(self) -> bool:
        """Check if transaction passed validation."""
        return self.processing_metadata.validation_passed
    
    def is_duplicate(self) -> bool:
        """Check if transaction is detected as duplicate."""
        return self.processing_metadata.duplicate_detected
    
    def is_ready_for_invoice(self) -> bool:
        """Check if transaction is ready for invoice generation."""
        return (
            self.status == ProcessingStatus.READY_FOR_INVOICE and
            self.is_valid() and
            not self.is_duplicate() and
            self.processing_metadata.risk_level != TransactionRisk.CRITICAL
        )
    
    def is_nigerian_compliant(self) -> bool:
        """Check if transaction meets Nigerian regulatory requirements."""
        return (
            self.enrichment_data.nigerian_compliance_level == "compliant" and
            not self.enrichment_data.regulatory_flags
        )
    
    def requires_manual_review(self) -> bool:
        """Check if transaction requires manual review."""
        return (
            self.processing_metadata.risk_level in [TransactionRisk.HIGH, TransactionRisk.CRITICAL] or
            self.enrichment_data.nigerian_compliance_level == "requires_review" or
            self.processing_metadata.confidence_score < 0.5
        )
    
    # Information extraction methods
    
    def get_customer_info(self) -> Dict[str, Any]:
        """Get enriched customer information."""
        return {
            'id': self.enrichment_data.customer_id,
            'name': self.enrichment_data.customer_name,
            'type': self.enrichment_data.customer_type,
            'matched': self.enrichment_data.customer_matched,
            'confidence': self.enrichment_data.customer_confidence
        }
    
    def get_risk_assessment(self) -> Dict[str, Any]:
        """Get comprehensive risk assessment information."""
        validation_issues = 0
        duplicate_matches = 0
        
        if self.validation_result and hasattr(self.validation_result, 'issues'):
            validation_issues = len(self.validation_result.issues) if self.validation_result.issues else 0
        
        if self.duplicate_result and hasattr(self.duplicate_result, 'matches'):
            duplicate_matches = len(self.duplicate_result.matches) if self.duplicate_result.matches else 0
        
        return {
            'level': self.processing_metadata.risk_level.value,
            'confidence': self.processing_metadata.confidence_score,
            'flags': self.enrichment_data.amount_risk_flags,
            'validation_issues': validation_issues,
            'duplicate_matches': duplicate_matches,
            'requires_review': self.requires_manual_review(),
            'regulatory_flags': self.enrichment_data.regulatory_flags
        }
    
    def get_categorization_info(self) -> Dict[str, Any]:
        """Get transaction categorization information."""
        return {
            'primary_category': self.enrichment_data.primary_category,
            'sub_category': self.enrichment_data.sub_category,
            'business_purpose': self.enrichment_data.business_purpose,
            'patterns': self.enrichment_data.transaction_patterns,
            'merchant_identified': self.enrichment_data.merchant_identified,
            'merchant_name': self.enrichment_data.merchant_name
        }
    
    def get_nigerian_compliance_info(self) -> Dict[str, Any]:
        """Get Nigerian regulatory compliance information."""
        return {
            'compliance_level': self.enrichment_data.nigerian_compliance_level,
            'tax_implications': self.enrichment_data.tax_implications,
            'regulatory_flags': self.enrichment_data.regulatory_flags,
            'is_compliant': self.is_nigerian_compliant(),
            'currency_compliant': self.currency == 'NGN'
        }
    
    def get_processing_summary(self) -> Dict[str, Any]:
        """Get summary of processing pipeline execution."""
        return {
            'processing_timestamp': self.processing_metadata.processing_timestamp.isoformat(),
            'processing_duration': self.processing_metadata.processing_duration,
            'pipeline_version': self.processing_metadata.pipeline_version,
            'connector_type': self.connector_type.value,
            'status': self.status.value,
            'confidence_score': self.processing_metadata.confidence_score,
            'risk_level': self.processing_metadata.risk_level.value,
            'stage_durations': {
                'validation': self.processing_metadata.validation_stage_duration,
                'duplicate_detection': self.processing_metadata.duplicate_detection_duration,
                'amount_validation': self.processing_metadata.amount_validation_duration,
                'business_rules': self.processing_metadata.business_rules_duration,
                'pattern_matching': self.processing_metadata.pattern_matching_duration,
                'enrichment': self.processing_metadata.enrichment_duration
            },
            'processing_notes': self.processing_metadata.processing_notes
        }
    
    def get_connector_specific_data(self) -> Dict[str, Any]:
        """Get connector-specific enrichment data."""
        connector_data = {}
        
        if self.connector_type.value.startswith('erp_'):
            connector_data.update({
                'invoice_number': self.enrichment_data.erp_invoice_number,
                'customer_code': self.enrichment_data.erp_customer_code,
                'cost_center': self.enrichment_data.erp_cost_center,
                'original_metadata': self.original_transaction.erp_metadata
            })
        elif self.connector_type.value.startswith('banking_'):
            connector_data.update({
                'account_verified': self.enrichment_data.bank_account_verified,
                'transaction_channel': self.enrichment_data.transaction_channel,
                'original_metadata': self.original_transaction.banking_metadata
            })
        elif self.connector_type.value.startswith('pos_'):
            connector_data.update({
                'terminal_id': self.enrichment_data.pos_terminal_id,
                'receipt_number': self.enrichment_data.receipt_number,
                'original_metadata': self.original_transaction.pos_metadata
            })
        elif self.connector_type.value.startswith('crm_'):
            connector_data.update({
                'service_type': self.enrichment_data.service_type,
                'project_id': self.enrichment_data.project_id,
                'original_metadata': self.original_transaction.crm_metadata
            })
        
        return connector_data
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to comprehensive dictionary representation."""
        return {
            # Core transaction data
            'id': self.id,
            'amount': str(self.amount),
            'date': self.date.isoformat(),
            'description': self.description,
            'account_number': self.account_number,
            'reference': self.reference,
            'currency': self.currency,
            'source_system': self.source_system,
            'category': self.category,
            'connector_type': self.connector_type.value,
            
            # Processing status
            'status': self.status.value,
            'is_valid': self.is_valid(),
            'is_duplicate': self.is_duplicate(),
            'is_ready_for_invoice': self.is_ready_for_invoice(),
            'is_nigerian_compliant': self.is_nigerian_compliant(),
            'requires_manual_review': self.requires_manual_review(),
            
            # Detailed information
            'customer_info': self.get_customer_info(),
            'risk_assessment': self.get_risk_assessment(),
            'categorization_info': self.get_categorization_info(),
            'nigerian_compliance_info': self.get_nigerian_compliance_info(),
            'processing_summary': self.get_processing_summary(),
            'connector_specific_data': self.get_connector_specific_data(),
            
            # Original transaction
            'original_transaction': self.original_transaction.to_dict()
        }
    
    def to_invoice_data(self) -> Dict[str, Any]:
        """Convert to invoice-ready data format for FIRS submission."""
        return {
            'invoice_id': self.id,
            'invoice_number': (
                self.enrichment_data.erp_invoice_number or 
                self.reference or 
                f"INV-{self.id}"
            ),
            'invoice_date': self.date.isoformat(),
            'amount': str(self.amount),
            'currency': self.currency,
            'description': self.description,
            'customer_info': self.get_customer_info(),
            'tax_info': {
                'vat_amount': self.original_transaction.get_field_value('vat_amount'),
                'tax_implications': self.enrichment_data.tax_implications
            },
            'compliance_status': {
                'nigerian_compliant': self.is_nigerian_compliant(),
                'regulatory_flags': self.enrichment_data.regulatory_flags,
                'compliance_level': self.enrichment_data.nigerian_compliance_level
            },
            'processing_metadata': {
                'processed_timestamp': self.processing_metadata.processing_timestamp.isoformat(),
                'confidence_score': self.processing_metadata.confidence_score,
                'connector_type': self.connector_type.value,
                'pipeline_version': self.processing_metadata.pipeline_version
            }
        }
    
    @classmethod
    def from_raw_transaction(
        cls,
        transaction: UniversalTransaction,
        connector_type: ConnectorType,
        validation_result: Any,
        duplicate_result: Any,
        processing_duration: float = 0.0,
        pipeline_version: str = "2.0.0"
    ) -> 'UniversalProcessedTransaction':
        """
        Create UniversalProcessedTransaction from raw transaction and processing results.
        
        Args:
            transaction: Original universal transaction
            connector_type: Type of connector
            validation_result: Validation results
            duplicate_result: Duplicate detection results
            processing_duration: Time taken to process
            pipeline_version: Version of processing pipeline
            
        Returns:
            UniversalProcessedTransaction instance
        """
        
        # Determine risk level
        risk_level = TransactionRisk.LOW
        if duplicate_result and hasattr(duplicate_result, 'is_duplicate') and duplicate_result.is_duplicate:
            risk_level = TransactionRisk.HIGH
        elif validation_result and hasattr(validation_result, 'is_valid') and not validation_result.is_valid:
            if hasattr(validation_result, 'critical_count') and validation_result.critical_count > 0:
                risk_level = TransactionRisk.CRITICAL
            elif hasattr(validation_result, 'errors_count') and validation_result.errors_count > 0:
                risk_level = TransactionRisk.HIGH
            elif hasattr(validation_result, 'warnings_count') and validation_result.warnings_count > 2:
                risk_level = TransactionRisk.MEDIUM
        
        # Calculate confidence score
        confidence_score = 1.0
        if validation_result and hasattr(validation_result, 'issues') and validation_result.issues:
            critical_count = getattr(validation_result, 'critical_count', 0)
            errors_count = getattr(validation_result, 'errors_count', 0)
            warnings_count = getattr(validation_result, 'warnings_count', 0)
            
            confidence_score -= (critical_count * 0.3 + errors_count * 0.2 + warnings_count * 0.1)
        
        if duplicate_result and hasattr(duplicate_result, 'is_duplicate') and duplicate_result.is_duplicate:
            confidence_score -= 0.5
        
        confidence_score = max(0.0, confidence_score)
        
        # Determine processing status
        is_duplicate = duplicate_result and hasattr(duplicate_result, 'is_duplicate') and duplicate_result.is_duplicate
        is_valid = not validation_result or not hasattr(validation_result, 'is_valid') or validation_result.is_valid
        has_critical_errors = (validation_result and 
                              hasattr(validation_result, 'critical_count') and 
                              validation_result.critical_count > 0)
        
        if is_duplicate:
            status = ProcessingStatus.DUPLICATE
        elif has_critical_errors:
            status = ProcessingStatus.FAILED
        elif is_valid:
            status = ProcessingStatus.VALIDATED
        else:
            status = ProcessingStatus.PENDING
        
        # Create processing metadata
        processing_metadata = ProcessingMetadata(
            processing_timestamp=datetime.utcnow(),
            processing_duration=processing_duration,
            pipeline_version=pipeline_version,
            connector_type=connector_type,
            validation_passed=is_valid,
            duplicate_detected=is_duplicate,
            risk_level=risk_level,
            confidence_score=confidence_score,
            processing_notes=[]
        )
        
        # Create empty enrichment data (to be filled by enrichment pipeline)
        enrichment_data = EnrichmentData()
        
        return cls(
            original_transaction=transaction,
            validation_result=validation_result,
            duplicate_result=duplicate_result,
            processing_metadata=processing_metadata,
            enrichment_data=enrichment_data,
            status=status,
            connector_type=connector_type
        )


# Utility functions for working with processed transactions

def filter_ready_for_invoice(
    processed_transactions: List[UniversalProcessedTransaction]
) -> List[UniversalProcessedTransaction]:
    """Filter transactions that are ready for invoice generation."""
    return [tx for tx in processed_transactions if tx.is_ready_for_invoice()]


def filter_nigerian_compliant(
    processed_transactions: List[UniversalProcessedTransaction]
) -> List[UniversalProcessedTransaction]:
    """Filter transactions that are Nigerian compliant."""
    return [tx for tx in processed_transactions if tx.is_nigerian_compliant()]


def group_by_connector_type(
    processed_transactions: List[UniversalProcessedTransaction]
) -> Dict[ConnectorType, List[UniversalProcessedTransaction]]:
    """Group transactions by connector type."""
    grouped = {}
    
    for tx in processed_transactions:
        if tx.connector_type not in grouped:
            grouped[tx.connector_type] = []
        grouped[tx.connector_type].append(tx)
    
    return grouped


def group_by_customer(
    processed_transactions: List[UniversalProcessedTransaction]
) -> Dict[str, List[UniversalProcessedTransaction]]:
    """Group transactions by customer ID."""
    grouped = {}
    
    for tx in processed_transactions:
        customer_id = tx.enrichment_data.customer_id or "unknown"
        if customer_id not in grouped:
            grouped[customer_id] = []
        grouped[customer_id].append(tx)
    
    return grouped


def calculate_batch_statistics(
    processed_transactions: List[UniversalProcessedTransaction]
) -> Dict[str, Any]:
    """Calculate statistics for a batch of processed transactions."""
    
    if not processed_transactions:
        return {}
    
    total_count = len(processed_transactions)
    valid_count = sum(1 for tx in processed_transactions if tx.is_valid())
    duplicate_count = sum(1 for tx in processed_transactions if tx.is_duplicate())
    ready_count = sum(1 for tx in processed_transactions if tx.is_ready_for_invoice())
    compliant_count = sum(1 for tx in processed_transactions if tx.is_nigerian_compliant())
    
    risk_breakdown = {}
    for risk_level in TransactionRisk:
        risk_breakdown[risk_level.value] = sum(
            1 for tx in processed_transactions 
            if tx.processing_metadata.risk_level == risk_level
        )
    
    connector_breakdown = {}
    for connector_type in ConnectorType:
        connector_breakdown[connector_type.value] = sum(
            1 for tx in processed_transactions
            if tx.connector_type == connector_type
        )
    
    total_amount = sum(tx.amount for tx in processed_transactions)
    average_confidence = sum(
        tx.processing_metadata.confidence_score for tx in processed_transactions
    ) / total_count
    
    return {
        'total_transactions': total_count,
        'valid_transactions': valid_count,
        'duplicate_transactions': duplicate_count,
        'ready_for_invoice': ready_count,
        'nigerian_compliant': compliant_count,
        'validation_rate': valid_count / total_count if total_count > 0 else 0,
        'duplicate_rate': duplicate_count / total_count if total_count > 0 else 0,
        'invoice_ready_rate': ready_count / total_count if total_count > 0 else 0,
        'compliance_rate': compliant_count / total_count if total_count > 0 else 0,
        'risk_breakdown': risk_breakdown,
        'connector_breakdown': connector_breakdown,
        'total_amount': str(total_amount),
        'average_confidence_score': average_confidence
    }